sum_err_pr = sum(err_pr)
err_pr2 = err_pr^2
CME = sum(err_pr2)/length(pr)
# Resp CME 9
# 5
y2 <- as.numeric(X2)
reg = glm(y2~X3+X4+X5+X6+X7,family = binomial())
yest = exp(reg$coefficients[1]+reg$coefficients[2]*X3+
reg$coefficients[3]*X4+reg$coefficients[4]*X5+
reg$coefficients[5]*X6+reg$coefficients[6]*X7)/
(1+exp(reg$coefficients[1]+reg$coefficients[2]*X3+
reg$coefficients[3]*X4+reg$coefficients[4]*X5+
reg$coefficients[5]*X6+reg$coefficients[6]*X7))
min_max <- sort(yest)
# min : 0.1064938
min(min_max)
# max : 0.4845855
max(min_max)
#literal 10
yest1 = round(yest)
error = ((yest1==y2)*1) #10
porc_acert = sum(error)/length(y2) # accuracy --- exactitud
# resp accuracy : 0.0228471
library('REdaS')
kmo = KMOS(x=datos2)
# 7
matriz = cbind(X3 ,X4 ,X5 ,X6 ,X7 ,X8 ,X9 ,X10 ,X11 ,X12 ,X13 ,X14 ,X15 ,X16 ,X17 ,X18 ,X19 ,X20 ,X21 ,X22 ,X23 ,X24 ,X25 ,X26 ,X27 ,X28 ,X29 ,X30 ,X31 ,X32)
pca = prcomp(matriz, center = TRUE, scale. = TRUE)
print(pca)
plot(pca, type = "l")
summary(pca)
# 8
# Componentes Principales
cp = predict(pca,matriz)
cp = as.data.frame(cp)
reg_2=lm(y ~ cp$PC1+cp$PC2+cp$PC3+cp$PC4+cp$PC5+cp$PC6+cp$PC7+cp$PC8+cp$PC9+cp$PC10+cp$PC11+cp$PC12cp$PC13+cp$PC14+cp$PC15+cp$PC16+cp$PC17+cp$PC18+cp$PC19+cp$PC20+cp$PC21+cp$PC22+cp$PC23+cp$PC24+cp$PC25+cp$PC26+cp$PC27+cp$PC28+cp$PC29+cp$PC30)
summary(reg_2)
library(readr)
wdbc <- read_csv("wdbc.data" ,col_names = FALSE)
#View(wdbc)
datos <- as.data.frame(wdbc)
datos2 <- datos[,-1] #Delete ID
# convirtiendo los tumores Malignos en 1
# y los Benignos en 0
datos2$X2[datos2$X2=="M"] <- 1
datos2$X2[datos2$X2=="B"] <- 0
X2 <- datos2$X2
X3 <- datos2$X3
X4 <- datos2$X4
X5 <- datos2$X5
X6 <- datos2$X6
X7 <- datos2$X7
X8 <- datos2$X8
X9 <- datos2$X9
X10<- datos2$X10
X11<- datos2$X11
X12<- datos2$X12
X13<- datos2$X13
X14<- datos2$X14
X15<- datos2$X15
X16<- datos2$X16
X17<- datos2$X17
X18<- datos2$X18
X19<- datos2$X19
X20<- datos2$X20
X21<- datos2$X21
X22<- datos2$X22
X23<- datos2$X23
X24<- datos2$X24
X25<- datos2$X25
X26<- datos2$X26
X27<- datos2$X27
X28<- datos2$X28
X29<- datos2$X29
X30<- datos2$X30
X31<- datos2$X31
X32<- datos2$X32
M <-  cbind(x2,X3 ,X4 ,X5 ,X6 ,X7 ,X8 ,X9 ,X10 ,X11 ,X12 ,X13 ,X14 ,X15 ,X16 ,X17 ,X18 ,X19 ,X20 ,X21 ,X22 ,X23 ,X24 ,X25 ,X26 ,X27 ,X28 ,X29 ,X30 ,X31 ,X32)
C <- cor(M)
#Multicolinealidad
MC <- C
MC[MC == 1] <- 0
max(MC)
## el max 0.9978553
min(C)
## el min -0.3116308
dim(C)
# dimension de 30 x 30
#3
d = dist(datos2, method = "euclidean")
max(d)
## el max 4739.089
min(d)
## el min 3.815967
# dimension de 30 x 30
# 4
Vx5 <- as.integer(X5) #Variable 5
y<- c(1:length(Vx5))
n = 5 # ventana
ma <- function(y,n){filter(y,rep(1/n,n), sides=1)}
wind = ma(y,n)
pr = wind[n:(length(wind)-1)]
err_pr = y[n+1:(length(y)-n)]-pr
sum_err_pr = sum(err_pr)
err_pr2 = err_pr^2
CME = sum(err_pr2)/length(pr)
# Resp CME 9
# 5
y2 <- as.numeric(X2)
reg = glm(y2~X3+X4+X5+X6+X7,family = binomial())
yest = exp(reg$coefficients[1]+reg$coefficients[2]*X3+
reg$coefficients[3]*X4+reg$coefficients[4]*X5+
reg$coefficients[5]*X6+reg$coefficients[6]*X7)/
(1+exp(reg$coefficients[1]+reg$coefficients[2]*X3+
reg$coefficients[3]*X4+reg$coefficients[4]*X5+
reg$coefficients[5]*X6+reg$coefficients[6]*X7))
min_max <- sort(yest)
# min : 0.1064938
min(min_max)
# max : 0.4845855
max(min_max)
#literal 10
yest1 = round(yest)
error = ((yest1==y2)*1) #10
porc_acert = sum(error)/length(y2) # accuracy --- exactitud
# resp accuracy : 0.0228471
library('REdaS')
kmo = KMOS(x=datos2)
# 7
matriz = cbind(X3 ,X4 ,X5 ,X6 ,X7 ,X8 ,X9 ,X10 ,X11 ,X12 ,X13 ,X14 ,X15 ,X16 ,X17 ,X18 ,X19 ,X20 ,X21 ,X22 ,X23 ,X24 ,X25 ,X26 ,X27 ,X28 ,X29 ,X30 ,X31 ,X32)
pca = prcomp(matriz, center = TRUE, scale. = TRUE)
print(pca)
plot(pca, type = "l")
summary(pca)
# 8
# Componentes Principales
cp = predict(pca,matriz)
cp = as.data.frame(cp)
reg_2=lm(y ~ cp$PC1+cp$PC2+cp$PC3+cp$PC4+cp$PC5+cp$PC6+cp$PC7+cp$PC8+cp$PC9+cp$PC10+cp$PC11+cp$PC12+cp$PC13+cp$PC14+cp$PC15+cp$PC16+cp$PC17+cp$PC18+cp$PC19+cp$PC20+cp$PC21+cp$PC22+cp$PC23+cp$PC24+cp$PC25+cp$PC26+cp$PC27+cp$PC28+cp$PC29+cp$PC30)
summary(reg_2)
View(cp)
library(readr)
wdbc <- read_csv("wine.data" )
View(wdbc)
library(readr)
wine <- read_csv("wine.data" ,col_names = FALSE)
View(wine)
library(readr)
# 1. Consumir el archivo wine.data en formato CSV.
# Todos los literales posteriores trabajarán con este dataset
wine <- read_csv("wine.data" ,col_names = FALSE)
View(wine)
# 2. Obtenga la ecuación de regresión estimada en la que
# se emplee Malic acid y Total phenols para predecir el Color intensity
x1 = wine$X2
x2 = wine$X6
y = wine$X10
reg = lm(y~x1+x2)
summary(reg)
library(readr)
# 1. Consumir el archivo wine.data en formato CSV.
# Todos los literales posteriores trabajarán con este dataset
wine <- read_csv("wine.data" ,col_names = FALSE)
View(wine)
# 2. Obtenga la ecuación de regresión estimada en la que
# se emplee Malic acid y Total phenols para predecir el Color intensity
x1 = wine$X2 # Malic acid
x2 = wine$X6 # Total phenols
y = wine$X10 # Color intensity
reg = lm(y~x1+x2)
summary(reg)
0.0616 *100
178-2-1
1.645 > 0.30401
1.645 > 0.00521
library(readr)
# 1. Consumir el archivo wine.data en formato CSV.
# Todos los literales posteriores trabajarán con este dataset
wine <- read_csv("wine.data" ,col_names = FALSE)
View(wine)
# 2. Obtenga la ecuación de regresión estimada en la que
# se emplee Malic acid y Total phenols para predecir el Color intensity
x1 = wine$X2 # Malic acid
x2 = wine$X6 # Total phenols
y  = wine$X10 # Color intensity
reg = lm(y~x1+x2)
# La bondad de ajuste del modelo generado en el literal
# 2. Haga un comentario sobre la bondad del ajuste
# summary(reg)
# Multiple R-squared:  0.0616
# Existe un 6.167% por lo cuando nuestra bonda de ajunte es mala
# ¿Indica la prueba t que hay una relación significante entre las variables
# independientes y dependiente del modelo del literal 2?. Use un nivel de
# significancia del 95% y el método del valor crítico
# prubea de x1 t 1.645 > 0.30401 [1] TRUE
# prueba de x2 t 1.645 > 0.00521 [1] TRUE
# 5. Para el literal anterior, determine el intervalo de confianza del
# coeficiente de regresión que representa a la pendiente, del modelo de regresión
# lineal (0.5 puntos).
b1= 0.055289
sb1=0.053631
b2= 0.008624
sb2= 0.003048
i_conf_b1_pos = b1+1.645*(sb1)
i_conf_b1_neg =  b1-1.645*(sb1)
i_conf_b2_pos = b2+1.645*(sb2)
i_conf_b2_neg =  b2-1.645*(sb2)
# La bondad de ajuste del modelo generado en el literal
# 2. Haga un comentario sobre la bondad del ajuste
summary(reg)
i_conf_b1_pos
i_conf_b1_neg
i_conf_b2_pos
i_conf_b2_neg
plot(reg)
# 8. Existe algún outlier, para el literal 2?. Utilice todos los métodos posibles
# justifique sus respuestas. Emplee como nivel de significancia 0.05 (1 punto).
rs= rstandard(reg)
rs
sort(rs)
inf=influence(reg)
inf
#datos influyentes
hi=inf$hat
hi
sort(hi)
n = length(x)
n = length(y)
n
umbral  = 3*(2+1)/n
umbral
h1> umbral
library(readr)
# 1. Consumir el archivo wine.data en formato CSV.
# Todos los literales posteriores trabajarán con este dataset
wine <- read_csv("wine.data" ,col_names = FALSE)
View(wine)
# 2. Obtenga la ecuación de regresión estimada en la que
# se emplee Malic acid y Total phenols para predecir el Color intensity
x1 = wine$X2 # Malic acid
x2 = wine$X6 # Total phenols
y  = wine$X10 # Color intensity
reg = lm(y~x1+x2)
# La bondad de ajuste del modelo generado en el literal
# 2. Haga un comentario sobre la bondad del ajuste
summary(reg)
# Multiple R-squared:  0.0616
# Existe un 6.167% por lo cuando nuestra bonda de ajunte es mala
# ¿Indica la prueba t que hay una relación significante entre las variables
# independientes y dependiente del modelo del literal 2?. Use un nivel de
# significancia del 95% y el método del valor crítico
# prubea de x1 t 1.645 > 0.30401 [1] TRUE
# prueba de x2 t 1.645 > 0.00521 [1] TRUE
# 5. Para el literal anterior, determine el intervalo de confianza del
# coeficiente de regresión que representa a la pendiente, del modelo de regresión
# lineal (0.5 puntos).
b1= 0.055289
sb1=0.053631
b2= 0.008624
sb2= 0.003048
i_conf_b1_pos = b1+1.645*(sb1) # 0.143512
i_conf_b1_neg =  b1-1.645*(sb1)# -0.032934
i_conf_b2_pos = b2+1.645*(sb2) # 0.01363796
i_conf_b2_neg =  b2-1.645*(sb2) # 0.00361004
# 6. El modelo del literal 2,
# tiene homocedasticidad? (0.5 puntos).
# 7. Para el literal 2, se cumple que las perturbaciones siguen una
# distribución normal. Justifique su respuesta, gráficamente. (0.5 puntos).
# 8. Existe algún outlier, para el literal 2?. Utilice todos los métodos posibles
# justifique sus respuestas. Emplee como nivel de significancia 0.05 (1 punto).
plot(reg)
# superal el umbral de -2 a 2 esto se puede ver de mejor mejor con el grafico Normal Q-Q
#  9. Existe algún valor influyente, para el literal 2?.
# Utilice todos los métodos posibles y justifique sus respuestas (1 punto).
inf=influence(reg)
#datos influyentes
hi=inf$hat
n = length(y)
umbral  = 3*(2+1)/n
hi> umbral
reg = lm(y~x11+x12+x13)
library(readr)
# 1. Consumir el archivo wine.data en formato CSV.
# Todos los literales posteriores trabajarán con este dataset
wine <- read_csv("wine.data" ,col_names = FALSE)
View(wine)
# 2. Obtenga la ecuación de regresión estimada en la que
# se emplee Malic acid y Total phenols para predecir el Color intensity
x1 = wine$X2 # Malic acid
x2 = wine$X6 # Total phenols
y  = wine$X10 # Color intensity
reg = lm(y~x1+x2)
# La bondad de ajuste del modelo generado en el literal
# 2. Haga un comentario sobre la bondad del ajuste
summary(reg)
# Multiple R-squared:  0.0616
# Existe un 6.167% por lo cuando nuestra bonda de ajunte es mala
# ¿Indica la prueba t que hay una relación significante entre las variables
# independientes y dependiente del modelo del literal 2?. Use un nivel de
# significancia del 95% y el método del valor crítico
# prubea de x1 t 1.645 > 0.30401 [1] TRUE
# prueba de x2 t 1.645 > 0.00521 [1] TRUE
# 5. Para el literal anterior, determine el intervalo de confianza del
# coeficiente de regresión que representa a la pendiente, del modelo de regresión
# lineal (0.5 puntos).
b1= 0.055289
sb1=0.053631
b2= 0.008624
sb2= 0.003048
i_conf_b1_pos = b1+1.645*(sb1) # 0.143512
i_conf_b1_neg =  b1-1.645*(sb1)# -0.032934
i_conf_b2_pos = b2+1.645*(sb2) # 0.01363796
i_conf_b2_neg =  b2-1.645*(sb2) # 0.00361004
# 6. El modelo del literal 2,
# tiene homocedasticidad? (0.5 puntos).
# 7. Para el literal 2, se cumple que las perturbaciones siguen una
# distribución normal. Justifique su respuesta, gráficamente. (0.5 puntos).
# 8. Existe algún outlier, para el literal 2?. Utilice todos los métodos posibles
# justifique sus respuestas. Emplee como nivel de significancia 0.05 (1 punto).
plot(reg)
# superal el umbral de -2 a 2 esto se puede ver de mejor mejor con el grafico Normal Q-Q
#  9. Existe algún valor influyente, para el literal 2?.
# Utilice todos los métodos posibles y justifique sus respuestas (1 punto).
inf=influence(reg)
#datos influyentes
hi=inf$hat
n = length(y)
umbral  = 3*(2+1)/n
hi > umbral
# no hay niguun valor influyente
# 10. Obtenga la ecuación de regresión estimada en la que se emplee Flavanoids,
# Magnesium y Alcohol para predecir el Color intensity  (1 punto).
x11 = wine$X7
x12 = wine$X5
x13 = wine$X1
reg = lm(y~x11+x12+x13)
yest=reg$coefficients[1]+reg$coefficients[2]*x11+reg$coefficients[3]*x12+reg$coefficients{4}*x13
yest=reg$coefficients[1]+reg$coefficients[2]*x11+reg$coefficients[3]*x12+reg$coefficients[4]*x13
reg
library(readr)
# 1. Consumir el archivo wine.data en formato CSV.
# Todos los literales posteriores trabajarán con este dataset
wine <- read_csv("wine.data" ,col_names = FALSE)
View(wine)
# 2. Obtenga la ecuación de regresión estimada en la que
# se emplee Malic acid y Total phenols para predecir el Color intensity
x1 = wine$X2 # Malic acid
x2 = wine$X6 # Total phenols
y  = wine$X10 # Color intensity
reg = lm(y~x1+x2)
yest=reg$coefficients[1]+reg$coefficients[2]*x1+reg$coefficients[3]*x2
# La bondad de ajuste del modelo generado en el literal
# 2. Haga un comentario sobre la bondad del ajuste
summary(reg)
# Multiple R-squared:  0.0616
# Existe un 6.167% por lo cuando nuestra bonda de ajunte es mala
# ¿Indica la prueba t que hay una relación significante entre las variables
# independientes y dependiente del modelo del literal 2?. Use un nivel de
# significancia del 95% y el método del valor crítico
# prubea de x1 t 1.645 > 0.30401 [1] TRUE
# prueba de x2 t 1.645 > 0.00521 [1] TRUE
# 5. Para el literal anterior, determine el intervalo de confianza del
# coeficiente de regresión que representa a la pendiente, del modelo de regresión
# lineal (0.5 puntos).
b1= 0.055289
sb1=0.053631
b2= 0.008624
sb2= 0.003048
i_conf_b1_pos = b1+1.645*(sb1) # 0.143512
i_conf_b1_neg =  b1-1.645*(sb1)# -0.032934
i_conf_b2_pos = b2+1.645*(sb2) # 0.01363796
i_conf_b2_neg =  b2-1.645*(sb2) # 0.00361004
# 6. El modelo del literal 2,
# tiene homocedasticidad? (0.5 puntos).
# 7. Para el literal 2, se cumple que las perturbaciones siguen una
# distribución normal. Justifique su respuesta, gráficamente. (0.5 puntos).
# 8. Existe algún outlier, para el literal 2?. Utilice todos los métodos posibles
# justifique sus respuestas. Emplee como nivel de significancia 0.05 (1 punto).
plot(reg)
# superal el umbral de -2 a 2 esto se puede ver de mejor mejor con el grafico Normal Q-Q
#  9. Existe algún valor influyente, para el literal 2?.
# Utilice todos los métodos posibles y justifique sus respuestas (1 punto).
inf=influence(reg)
#datos influyentes
hi=inf$hat
n = length(y)
umbral  = 3*(2+1)/n
hi > umbral
# no hay niguun valor influyente
# 10. Obtenga la ecuación de regresión estimada en la que se emplee Flavanoids,
# Magnesium y Alcohol para predecir el Color intensity  (1 punto).
x11 = wine$X7
x12 = wine$X5
x13 = wine$X1
reg1 = lm(y~x11+x12+x13)
yest1=reg1$coefficients[1]+reg1$coefficients[2]*x11+reg1$coefficients[3]*x12+reg1$coefficients[4]*x13
summary(reg1)
plot(reg1)
sort(rs1)
plot(reg1)
plot(reg1)
sort(rs1)
rs1= rstandard(reg1)
sort(rs1)
# 12. Para el literal 10, indique si existe un outlier considerando
# el criterio de los residuales estadarizados (1 punto).
plot(reg1)
# 12. Para el literal 10, indique si existe un outlier considerando
# el criterio de los residuales estadarizados (1 punto).
plot(reg1)
sort(rs1)
datos2 <- wine[,-1] #Delete ID
View(wine)
View(datos2)
wine2 <- wine[-3,] #Delete ID
View(datos2)
library(readr)
# 1. Consumir el archivo wine.data en formato CSV.
# Todos los literales posteriores trabajarán con este dataset
wine <- read_csv("wine.data" ,col_names = FALSE)
#View(wine)
# 2. Obtenga la ecuación de regresión estimada en la que
# se emplee Malic acid y Total phenols para predecir el Color intensity
x1 = wine$X2 # Malic acid
x2 = wine$X6 # Total phenols
y  = wine$X10 # Color intensity
reg = lm(y~x1+x2)
yest=reg$coefficients[1]+reg$coefficients[2]*x1+reg$coefficients[3]*x2
# La bondad de ajuste del modelo generado en el literal
# 2. Haga un comentario sobre la bondad del ajuste
summary(reg)
# Multiple R-squared:  0.0616
# Existe un 6.167% por lo cuando nuestra bonda de ajunte es mala
# ¿Indica la prueba t que hay una relación significante entre las variables
# independientes y dependiente del modelo del literal 2?. Use un nivel de
# significancia del 95% y el método del valor crítico
# prubea de x1 t 1.645 > 0.30401 [1] TRUE
# prueba de x2 t 1.645 > 0.00521 [1] TRUE
# 5. Para el literal anterior, determine el intervalo de confianza del
# coeficiente de regresión que representa a la pendiente, del modelo de regresión
# lineal (0.5 puntos).
b1= 0.055289
sb1=0.053631
b2= 0.008624
sb2= 0.003048
i_conf_b1_pos = b1+1.645*(sb1) # 0.143512
i_conf_b1_neg =  b1-1.645*(sb1)# -0.032934
i_conf_b2_pos = b2+1.645*(sb2) # 0.01363796
i_conf_b2_neg =  b2-1.645*(sb2) # 0.00361004
# 6. El modelo del literal 2,
# tiene homocedasticidad? (0.5 puntos).
# 7. Para el literal 2, se cumple que las perturbaciones siguen una
# distribución normal. Justifique su respuesta, gráficamente. (0.5 puntos).
# 8. Existe algún outlier, para el literal 2?. Utilice todos los métodos posibles
# justifique sus respuestas. Emplee como nivel de significancia 0.05 (1 punto).
plot(reg)
# superal el umbral de -2 a 2 esto se puede ver de mejor mejor con el grafico Normal Q-Q
#  9. Existe algún valor influyente, para el literal 2?.
# Utilice todos los métodos posibles y justifique sus respuestas (1 punto).
inf=influence(reg)
#datos influyentes
hi=inf$hat
n = length(y)
umbral  = 3*(2+1)/n
hi > umbral
# no hay niguun valor influyente
# 10. Obtenga la ecuación de regresión estimada en la que se emplee Flavanoids,
# Magnesium y Alcohol para predecir el Color intensity  (1 punto).
x11 = wine$X7
x12 = wine$X5
x13 = wine$X1
reg1 = lm(y~x11+x12+x13)
yest1=reg1$coefficients[1]+reg1$coefficients[2]*x11+reg1$coefficients[3]*x12+reg1$coefficients[4]*x13
#11. Calcule la bondad de ajuste e indique la variable que
# aporta más información en el modelo del literal 10
summary(reg1)
#la variable que mas aporta x11 0.475521   0.078618   6.048 8.71e-09 ***
# Multiple R-squared:  0.3838
# Se puede no es un buen modelo ya que mi bondad de ajunte no supera el 0.7
# 12. Para el literal 10, indique si existe un outlier considerando
# el criterio de los residuales estadarizados (1 punto).
plot(reg1)
#  159          100          125           51
# 70           79          111           96
# 13. Eliminando la categoría 3 de la variable "Alcohol" Genere un modelo de regresión que le permita predecir las dos clases de alcohol en función de Flavanoids y Magnesium.
# Indique los coeficientes de regresión del modelo (no dividir el dataset)
wine2 <- wine[-3,] #Delete ID
View(datos2)
View(wine2)
View(wine)
View(wine)
wine2 <- wine[-3,] #Delete ID
wine2 <- wine[,-14] #Delete ID
View(wine2)
set.seed(7)
rows <- sample(nrow(wine2))
wine2<-wine2[rows,]
wine2
d = dim(wine2)
training  = round(d[1]*0.7)
training
# 6. El modelo del literal 2,
# tiene homocedasticidad? (0.5 puntos).
plot(reg)
M <- cbind(wine$X1,wine$X2,wine$X3,wine$X4,wine$X5,wine$X6,wine$X7,wine$X8,wine$X9,wine$X10,wine$X11,wine$X12,wine$X13)
C <- cor(M)
#Multicolinealidad
MC <- C
MC[MC == 1] <- 0
max(MC)
## el max 0.9765953
min(C)
